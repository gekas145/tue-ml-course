{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openml as oml\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Using GAMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use AutoML tool [GAMA](https://github.com/PGijsbers/gama/).\n",
    "The exercise is self-contained, but if you want to know more the documentation is found [here](https://pgijsbers.github.io/gama/develop/).\n",
    "First, make sure GAMA is installed and/or check the right version is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet gama\n",
    "# Note: On MacOS, you may also need to install openblas, e.g. with `brew install openblas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. You may continue :)\n"
     ]
    }
   ],
   "source": [
    "from packaging import version\n",
    "import gama\n",
    "if version.parse(gama.__version__) < version.parse(\"20.1.0\"):\n",
    "    print(\"GAMA is outdated. Please update now!\")\n",
    "else:\n",
    "    print(\"OK. You may continue :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*note*:\n",
    "> GAMA is under active development. Parts of the interface are still subject to change. We are also using small time budgets because the lab only lasts two hours. For that reason some of the results may be affected more than usual by the randomness inherent to evolutionary search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard use case on NO<sub>2</sub> data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lab session 1, we tested several models the predict **NO<sub>2</sub>** levels.\n",
    "Here we will use GAMA automatically find a pipeline for this task.\n",
    "First we have to fetch the data from OpenML, and split it into a train and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "no2 = oml.datasets.get_dataset(547)\n",
    "X, y, _, _ = no2.get_data(target=no2.default_target_attribute, dataset_format='dataframe');\n",
    "X = X.drop('day',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then import and use GAMA just like a scikit-learn classifier or regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from gama import GamaClassifier, GamaRegressor\n",
    "automl = GamaRegressor(\n",
    "    max_total_time=60, # in seconds\n",
    "    n_jobs=1,  # one subprocess\n",
    "    scoring='r2',  # metric to optimize for\n",
    "    verbosity=logging.WARNING,  # to get printed updates about search progress\n",
    "    output_directory=\"gama_log\",  # name for a log file to record search output in\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.1\n",
    "Starting AutoML is now as simple as calling `fit` with the training data. You can use the `score` function to get the model's score on the test set. Using GAMA, fit a model to the data and report the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gama.GamaRegressor.GamaRegressor at 0x1739e835dc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 1.1: Call fit and score\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4346160066885787"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the score compare to the maximum of `0.4796` found in lab 1?\n",
    "It's likely better(actually no, but it may be due to time constraint). Because the dataset is so small, even in one minute time GAMA can evaluate many pipelines.\n",
    "GAMA also considers more (and different) models than those from lab 1.\n",
    "\n",
    "The number of pipelines that have been evaluated should've been printed as cell output.\n",
    "But we can also have a closer look at which pipelines have been evaluated.\n",
    "We do this by parsing the log GAMA created (filename set by `keep_analysis_log`) with the builtin `GamaReport` parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_evaluations(df):\n",
    "    \"\"\" The GamaReport was initially developed for use within GAMA tooling.\n",
    "    For this reason it contains some hard to interpret, useless or internal data.\n",
    "    For clarity, we filter this out for you.\n",
    "    \"\"\"\n",
    "    df = df.drop(['id', 'length_cummax', 'relative_end'], axis=1)\n",
    "    df['length'] = -df['length']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing default after 0.0147s.\n",
      "\n",
      "search AsyncEA after 54.0401s.\n",
      "\n",
      "postprocess BestFitPostProcessing after 0.4540s.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "      <th>t_process</th>\n",
       "      <th>score</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>error</th>\n",
       "      <th>parent0</th>\n",
       "      <th>parent1</th>\n",
       "      <th>origin</th>\n",
       "      <th>n</th>\n",
       "      <th>r2</th>\n",
       "      <th>length</th>\n",
       "      <th>r2_cummax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12412</td>\n",
       "      <td>2024-07-11 19:34:23.360729</td>\n",
       "      <td>0 days 00:00:00.107636690</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>(0.2557328988449104, -1)</td>\n",
       "      <td>KNeighborsRegressor(data, KNeighborsRegressor....</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255733</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.255733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12412</td>\n",
       "      <td>2024-07-11 19:34:26.048777</td>\n",
       "      <td>0 days 00:00:01.241764545</td>\n",
       "      <td>1.218750</td>\n",
       "      <td>(0.46008729321912706, -2)</td>\n",
       "      <td>ExtraTreesRegressor(VarianceThreshold(data, Va...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>5</td>\n",
       "      <td>0.460087</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12412</td>\n",
       "      <td>2024-07-11 19:34:37.286786</td>\n",
       "      <td>0 days 00:00:00.164024591</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>(0.3858684615161588, -2)</td>\n",
       "      <td>KNeighborsRegressor(SelectPercentile(data, Sel...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>16</td>\n",
       "      <td>0.385868</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.567451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12412</td>\n",
       "      <td>2024-07-11 19:34:52.462747</td>\n",
       "      <td>0 days 00:00:01.957669735</td>\n",
       "      <td>1.609375</td>\n",
       "      <td>(0.5446952754113196, -2)</td>\n",
       "      <td>RandomForestRegressor(MinMaxScaler(data), Rand...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>23</td>\n",
       "      <td>0.544695</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.567451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12412</td>\n",
       "      <td>2024-07-11 19:35:06.499764</td>\n",
       "      <td>0 days 00:00:02.526159048</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>(0.5755489678240762, -2)</td>\n",
       "      <td>RandomForestRegressor(StandardScaler(data), Ra...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>29</td>\n",
       "      <td>0.575549</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.575549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pid                      start                  duration  t_process  \\\n",
       "1   12412 2024-07-11 19:34:23.360729 0 days 00:00:00.107636690   0.046875   \n",
       "5   12412 2024-07-11 19:34:26.048777 0 days 00:00:01.241764545   1.218750   \n",
       "16  12412 2024-07-11 19:34:37.286786 0 days 00:00:00.164024591   0.109375   \n",
       "23  12412 2024-07-11 19:34:52.462747 0 days 00:00:01.957669735   1.609375   \n",
       "29  12412 2024-07-11 19:35:06.499764 0 days 00:00:02.526159048   1.953125   \n",
       "\n",
       "                        score  \\\n",
       "1    (0.2557328988449104, -1)   \n",
       "5   (0.46008729321912706, -2)   \n",
       "16   (0.3858684615161588, -2)   \n",
       "23   (0.5446952754113196, -2)   \n",
       "29   (0.5755489678240762, -2)   \n",
       "\n",
       "                                             pipeline error  parent0  parent1  \\\n",
       "1   KNeighborsRegressor(data, KNeighborsRegressor....  None      NaN      NaN   \n",
       "5   ExtraTreesRegressor(VarianceThreshold(data, Va...  None      NaN      NaN   \n",
       "16  KNeighborsRegressor(SelectPercentile(data, Sel...  None      NaN      NaN   \n",
       "23  RandomForestRegressor(MinMaxScaler(data), Rand...  None      NaN      NaN   \n",
       "29  RandomForestRegressor(StandardScaler(data), Ra...  None      NaN      NaN   \n",
       "\n",
       "   origin   n        r2  length  r2_cummax  \n",
       "1     new   1  0.255733     1.0   0.255733  \n",
       "5     new   5  0.460087     2.0   0.500531  \n",
       "16    new  16  0.385868     2.0   0.567451  \n",
       "23    new  23  0.544695     2.0   0.567451  \n",
       "29    new  29  0.575549     2.0   0.575549  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gama.logging.GamaReport import GamaReport\n",
    "report = GamaReport(log_directory=\"gama_log\")\n",
    "evaluations = transform_evaluations(report.evaluations)\n",
    "evaluations.sample(5).sort_values(by='n')  # Show 5 random samples from the dataframe, but sort them by order of n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe has the following columns:\n",
    " - n: the n-th pipeline to be evaluated in search\n",
    " - start: start time of the evaluation\n",
    " - duration: the time it took to evaluate the model (in seconds)\n",
    " - r2: the r2 score of the pipeline (based on 5-fold cross-validation on the training data)\n",
    " - length: the number of steps in the pipeline times (i.e., length 2 means one preprocessing step and one estimator).\n",
    " - pipeline: the pipeline (more info below)\n",
    " - r2_cummax: the maximum r2 score found at evaluation `n`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2:\n",
    "Find the best pipeline of each length from the `evaluations` dataframe (or one of the best, in case of a tie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "      <th>t_process</th>\n",
       "      <th>score</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>error</th>\n",
       "      <th>parent0</th>\n",
       "      <th>parent1</th>\n",
       "      <th>origin</th>\n",
       "      <th>n</th>\n",
       "      <th>r2</th>\n",
       "      <th>length</th>\n",
       "      <th>r2_cummax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12412</td>\n",
       "      <td>2024-07-11 19:35:06.499764</td>\n",
       "      <td>0 days 00:00:02.526159048</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>(0.5755489678240762, -2)</td>\n",
       "      <td>RandomForestRegressor(StandardScaler(data), Ra...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>29</td>\n",
       "      <td>0.575549</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.575549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12412</td>\n",
       "      <td>2024-07-11 19:35:09.331104</td>\n",
       "      <td>0 days 00:00:01.092484713</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>(0.5005273931498501, -1)</td>\n",
       "      <td>ElasticNetCV(data, ElasticNetCV.l1_ratio=0.25,...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>31</td>\n",
       "      <td>0.500527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.575549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12412</td>\n",
       "      <td>2024-07-11 19:34:45.473268</td>\n",
       "      <td>0 days 00:00:00.374484062</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>(0.5004288080097752, -3)</td>\n",
       "      <td>LassoLarsCV(RobustScaler(StandardScaler(data))...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500429</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.567451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pid                      start                  duration  t_process  \\\n",
       "29  12412 2024-07-11 19:35:06.499764 0 days 00:00:02.526159048   1.953125   \n",
       "31  12412 2024-07-11 19:35:09.331104 0 days 00:00:01.092484713   0.812500   \n",
       "20  12412 2024-07-11 19:34:45.473268 0 days 00:00:00.374484062   0.343750   \n",
       "\n",
       "                       score  \\\n",
       "29  (0.5755489678240762, -2)   \n",
       "31  (0.5005273931498501, -1)   \n",
       "20  (0.5004288080097752, -3)   \n",
       "\n",
       "                                             pipeline error  parent0  parent1  \\\n",
       "29  RandomForestRegressor(StandardScaler(data), Ra...  None      NaN      NaN   \n",
       "31  ElasticNetCV(data, ElasticNetCV.l1_ratio=0.25,...  None      NaN      NaN   \n",
       "20  LassoLarsCV(RobustScaler(StandardScaler(data))...  None      NaN      NaN   \n",
       "\n",
       "   origin   n        r2  length  r2_cummax  \n",
       "29    new  29  0.575549     2.0   0.575549  \n",
       "31    new  31  0.500527     1.0   0.575549  \n",
       "20    new  20  0.500429     3.0   0.567451  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 1.2: Find the best pipeline of each length\n",
    "evaluations.sort_values('r2', ascending=False).drop_duplicates(['length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the progress of search, plot:\n",
    " - The `r2` score for each evaluation as a function of `n`, preferably only for those evaluations with an `r2` score of at least 0.\n",
    " - The maximum `r2` score as a function of `n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEGCAYAAABrQF4qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcoElEQVR4nO3de5SU9Z3n8feXvnCXa4sKCg1BUYMotmAWN8IwZsGjIW50ld2zY5LdQ5jEeMnZTUhM1NkJSZzNZvRsjIQYNJ7R8cQ4MJjBaDLJDrojDY1LwkUZsbsNJRmp7ubSxaVvfPePehrLppp++lL11FP9eZ3DoZ5b9feh5OOPbz3P7zF3R0REiteQqAsQEZHcUtCLiBQ5Bb2ISJFT0IuIFDkFvYhIkSuNuoBsJk6c6NOmTYu6DBGR2Ni+fXuDu1dk21aQQT9t2jRqamqiLkNEJDbM7N3utql1IyJS5BT0IiJFTkEvIlLkCrJHn01bWxuJRIKTJ09GXcqgMWzYMKZMmUJZWVnUpYhIP8Qm6BOJBKNHj2batGmYWdTlFD13p7GxkUQiQWVlZdTliEg/xKZ1c/LkSSZMmKCQzxMzY8KECfoXlEgRiE3QAwr5PNOft0hxiE3rRkSkUJxs6+Dvd7zHe4dODOj7jhhaysrrZwzoe4KCXkQktJNtHfzt1j+w5p/e4f2jLQAM5D98J44aqqAvFMePH+e2227jnXfeoaSkhJtvvpnvfve7UZclIjlyorWDZ6rf5Ueba0k2tzC/cjx/ffuVfGx6PL43VND3gbvz5S9/mcWLF9Pa2srixYt56aWXWLp0adSlicgAOt7azt9seZe1m2tpSLXyb2ZM4H8vv4prp0+IurReiWXQ/8WLu9lz4OiAvudlF5zDgzdf3u32+vp6li5dyqJFi3j99dfZsGEDAOXl5cydO5dEItHtse+//z4rV66ktrYWgMcff5wLLriAm266iV27dgHwve99j1QqxUMPPcTChQu56qqr2L59O8lkkqeffprvfOc77Ny5k9tvv51vfetb1NfXs2TJEq677jq2bNnCnDlz+OxnP8uDDz7IwYMHeeaZZ5g3bx5bt27l3nvv5cSJEwwfPpwnn3ySSy65hO9///vs2rWLdevWsXPnTpYvX87WrVsZMWLEwP2hisRUqqWdp1+v54lX62g61sq/nTmRuxfP5Jpp46MurU9iGfRR2bt3L08++SQ//OEPT687fPgwL774Ivfcc0+3x919991cf/31rF+/no6ODlKpFIcOHTrrzyovL2fz5s08+uijLFu2jO3btzN+/HhmzJjBfffdB8C+fft4/vnnWbt2Lddccw3PPvssr732Ghs3buTb3/42GzZsYNasWWzevJnS0lJ+/etf8/Wvf50XXniBe++9l4ULF7J+/XpWr17Nj370o0hD/sjxNv6m+l1a209FVoMIpEP+hTcSHD7exsJLKvjSn8zk6qnjoi6rX2IZ9GcbeefS1KlTufbaa08vt7e3s3z5cu6++26mT5/e7XG/+c1vePrppwEoKSlhzJgxPQb9Jz/5SQBmz57N5Zdfzvnnnw/A9OnT2b9/P2PHjqWyspLZs2cDcPnll7N48WLMjNmzZ1NfXw/AkSNHuPPOO3n77bcxM9ra2gAYMmQITz31FFdccQWf//znWbBgQd/+UAbI89v38z9f3htpDSKQ/nJ10SXncvfimVx54dioyxkQsQz6qIwcOfJDyytWrGDmzJnce++9vX6v0tJSTp36YPTa9cakoUOHAulA7nzdudze3v6hfbrul7nPN7/5TRYtWsT69eupr69n4cKFp495++23GTVqFAcOHOh1/QNtS20TUyeM4J/++6KoSxEpOrG6YaqQfOMb3+DIkSM88sgjPe67ePFiHn/8cQA6Ojo4evQokyZN4uDBgzQ2NtLS0sIvfvGLnNR55MgRJk+eDMBTTz31ofX33HMPmzdvprGxkZ///Oc5+flhnDrlbKtvYn5lPPufIoVOQd8HiUSC1atXs2fPHubOncuVV17JE0880e3+jz76KL/97W+ZPXs2V199Nbt376asrIwHHniA+fPnc9NNNzFr1qyc1PqVr3yFr33tayxYsICOjo7T6++77z6+8IUvcPHFF/OTn/yEVatWcfDgwZzU0JO97zdz5EQb8yvjdSWDSFyYu0ddwxmqqqq86xOm3nzzTS699NKIKhq88vHn/tT/reOhF/fw2lcXMWWcrvoR6Qsz2+7uVdm2aUQvkauua2Ly2OEKeZEc0ZexA2j16tU8//zzH1p32223cf/990dUUeFzd7bWNXH9xVmfaSwiAyBWQe/uBX278f33319UoZ6Ptt47yRSNx1qZP11fxIrkSqjWjZktMbO9ZrbPzFZl2b7QzI6Y2Y7g1wMZ2+rNbGewvqbrsWENGzaMxsbGvISPfPDgkWHDhuX052ypbQLQF7EiOdTjiN7MSoDHgBuABLDNzDa6+54uu77q7jd18zaL3L2hP4VOmTKFRCJBMpnsz9tIL3Q+SjCXquuamHTOUKZOUH9eJFfCtG7mAfvcvRbAzJ4DlgFdgz6nysrK9Ei7IuPuVNc2cm1MZgAUiaswrZvJwP6M5USwrquPmdnvzOwlM8uco8CBV8xsu5mt6O6HmNkKM6sxsxqN2geH+sbjHGxuYZ5ulBLJqTAj+mxDra6N8jeAqe6eMrMbgQ3AzGDbAnc/YGbnAr8ys7fcffMZb+i+FlgL6evow56AxNfWukYArtUXsSI5FWZEnwAuzFieAnxochR3P+ruqeD1JqDMzCYGyweC3w8C60m3gkSorm1i4qhyZlSMiroUkaIWJui3ATPNrNLMyoE7gI2ZO5jZeRY0Wc1sXvC+jWY20sxGB+tHAp8Adg3kCUh8Vdc1Ma9yvPrzIjnWY+vG3dvN7C7gZaAEWOfuu81sZbB9DXAr8Odm1g6cAO5wdzezScD64C9yKfCsu/8yR+ciMbK/6TjvHT7Bio93P72ziAyMUDdMBe2YTV3Wrcl4/QPgB1mOqwXm9LNGKUJb69LXz+uLWJHc01w3EonqukbGjijjkkmjoy5FpOgp6CUS1XVNXDNtPEOGqD8vkmsKesm7fz1ykncbj+tBIyJ5oqCXvKsOrp/X/DYi+aGgl7yrrmti9NBSLrvgnKhLERkUFPSSd9W1jVRNG0eJ+vMieaGgl7xKNrfwTvIY86erbSOSLwp6yavO6+f1RaxI/ijoJa+q6xoZUV7CRyePiboUkUFDQS95tbWuiaunjqOsRP/pieSL/rZJ3hw61spb/9qsto1IninoJW+21gf9eX0RK5JXCnrJm+raJoaWDuGKKerPi+STgl7yZmt9I1ddNJahpSVRlyIyqCjoJS+Onmxjz4GjmvZAJAIKesmLmvomTjnM1/NhRfJOQS95UV3bRFmJMfeicVGXIjLoKOglL7bUNTFnyliGlak/L5JvCnrJuWMt7ex674jaNiIRUdBLzm1/9xAdp1xfxIpEREEvOVdd10jJEOPqqerPi0RBQS85V13bxOzJYxg5tDTqUkQGpVBBb2ZLzGyvme0zs1VZti80syNmtiP49UDYY6W4nWjt4HeJw5rfRiRCPQ6xzKwEeAy4AUgA28xso7vv6bLrq+5+Ux+PjTV3Z3/TCU65R11Kwfn9e0do63B9ESsSoTD/lp4H7HP3WgAzew5YBoQJ6/4cGxs/frWWb296K+oyClbpEKNqmoJeJCphgn4ysD9jOQHMz7Lfx8zsd8AB4L+5++5eHIuZrQBWAFx00UUhyioctcljjB1RxoM3XxZ1KQVpyrgRnDOsLOoyRAatMEGf7QnOXXsUbwBT3T1lZjcCG4CZIY9Nr3RfC6wFqKqqilUPJNncwgVjhnPLVVOiLkVE5AxhvoxNABdmLE8hPWo/zd2PunsqeL0JKDOziWGOLQYNqRYmjh4adRkiIlmFCfptwEwzqzSzcuAOYGPmDmZ2nplZ8Hpe8L6NYY4tBsnmFipGKehFpDD12Lpx93Yzuwt4GSgB1rn7bjNbGWxfA9wK/LmZtQMngDvc3YGsx+boXCLh7jSkWpk4ujzqUkREsgp1B0vQjtnUZd2ajNc/AH4Q9thicvRkO60dpzSiF5GCpTtj+ynZ3AJAhXr0IlKgFPT91JAKgl4jehEpUAr6fuoc0euqGxEpVAr6fuoc0U/UiF5ECpSCvp+SzS2UDjHGDtednyJSmBT0/dSQamHCqHKGDMl2E7CISPQU9P2UbG7RFTciUtAU9P3UkGpVf15ECpqCvp8aUpr+QEQKm4K+H9LTH2hCMxEpbAr6fjhyoo22DlfrRkQKmoK+HzT9gYjEgYK+H5Knb5bSzJUiUrgU9P3QOaI/VyN6ESlgCvp+aEi1Apr+QEQKm4K+H5LNLZSVGGM0/YGIFDAFfT80pFqYOGoowVMURUQKkoK+HxpSmv5ARAqfgr4fks0t6s+LSMFT0PdDunWjSytFpLAp6Pvo1CmnIdWq1o2IFDwFfR8dPtFGxylNfyAihS9U0JvZEjPba2b7zGzVWfa7xsw6zOzWjHX1ZrbTzHaYWc1AFF0INP2BiMRFaU87mFkJ8BhwA5AAtpnZRnffk2W/h4GXs7zNIndvGIB6C4aeFSsicRFmRD8P2Ofute7eCjwHLMuy35eAF4CDA1hfwdKIXkTiIkzQTwb2ZywngnWnmdlk4BZgTZbjHXjFzLab2YrufoiZrTCzGjOrSSaTIcqKlkb0IhIXYYI+222f3mX5EeCr7t6RZd8F7j4XWAp80cw+nu2HuPtad69y96qKiooQZUUrmWqhvGQI5wzrsfslIhKpMCmVAC7MWJ4CHOiyTxXwXDAVwETgRjNrd/cN7n4AwN0Pmtl60q2gzf2uPGKdDwXX9AciUujCjOi3ATPNrNLMyoE7gI2ZO7h7pbtPc/dpwM+BL7j7BjMbaWajAcxsJPAJYNeAnkFE0g8F181SIlL4ehzRu3u7md1F+mqaEmCdu+82s5XB9mx9+U6TgPXBqLcUeNbdf9n/sqOXbG5h8thhUZchItKjUA1md98EbOqyLmvAu/tnMl7XAnP6UV/Baki1MGfKmKjLEBHpke6M7YOOU06jZq4UkZhQ0PfBoeOtnHJdWiki8aCg7wPdLCUicaKg7wPdLCUicaKg74POEb0urxSROFDQ90HniF6tGxGJAwV9HzSkWhlaOoRRQzX9gYgUPgV9H2j6AxGJEwV9H6SfFau2jYjEg4K+DzpH9CIicaCg7wON6EUkThT0vdTecYrGY61U6NJKEYkJBX0vNR1vxV2XVopIfCjoe+mDm6UU9CISDwr6XmpItQIa0YtIfCjoe6lBI3oRiRkFfS8lNf2BiMSMgr6XGppbGF5WwkhNfyAiMaGg76WkniwlIjGjoO+l9M1SuoZeROJDQd9LyWbdFSsi8aKg76WGVKtaNyISK6GC3syWmNleM9tnZqvOst81ZtZhZrf29tg4aOs4RdOxVo3oRSRWegx6MysBHgOWApcBy83ssm72exh4ubfHxkXTMd0sJSLxE2ZEPw/Y5+617t4KPAcsy7Lfl4AXgIN9ODYWNP2BiMRRmKCfDOzPWE4E604zs8nALcCa3h6b8R4rzKzGzGqSyWSIsvJPN0uJSByFCfpsz8vzLsuPAF91944+HJte6b7W3avcvaqioiJEWfnXOf1BhUb0IhIjYW7vTAAXZixPAQ502acKeC54hupE4EYzaw95bGx0jugnjtZ19CISH2GCfhsw08wqgfeAO4D/mLmDu1d2vjazp4BfuPsGMyvt6dg4aWhuZWR5CSPKNf2BiMRHj4nl7u1mdhfpq2lKgHXuvtvMVgbbu/blezx2YErPv2SqhYnqz4tIzIQamrr7JmBTl3VZA97dP9PTsXHV0Nyi/ryIxI7ujO2FpB4KLiIxpKDvhQbNXCkiMaSgD6m1/RSHj7dpRC8isaOgD6nxmC6tFJF4UtCH1NAczHOjEb2IxIyCPqRk6iSALq8UkdhR0IekEb2IxJWCPiRNaCYicaWgDynZ3MLooaUMKyuJuhQRkV5R0Iek6Q9EJK4U9CFp+gMRiSsFfUgNqRZdQy8isaSgDynZrHluRCSeFPQhtLR3cPRku1o3IhJLCvoQGlLpa+j1ZayIxJGCPgQ9K1ZE4kxBH0KyuXNCMwW9iMSPgj6EBt0VKyIxpqAPoXNEP2GkLq8UkfhR0IfQkGph9DBNfyAi8aSgD6Eh1aq2jYjEVqigN7MlZrbXzPaZ2aos25eZ2e/NbIeZ1ZjZdRnb6s1sZ+e2gSw+X3SzlIjEWWlPO5hZCfAYcAOQALaZ2UZ335Ox2z8CG93dzewK4GfArIzti9y9YQDrzquGVAuXXnBO1GWIiPRJmBH9PGCfu9e6eyvwHLAscwd3T7m7B4sjAaeIJDWhmYjEWJignwzsz1hOBOs+xMxuMbO3gH8APpexyYFXzGy7ma3oT7FRONnWQXNLu3r0IhJbYYLesqw7Y8Tu7uvdfRbwKeAvMzYtcPe5wFLgi2b28aw/xGxF0N+vSSaTIcrKj9M3S43SpZUiEk9hgj4BXJixPAU40N3O7r4ZmGFmE4PlA8HvB4H1pFtB2Y5b6+5V7l5VUVERsvzc081SIhJ3YYJ+GzDTzCrNrBy4A9iYuYOZfcTMLHg9FygHGs1spJmNDtaPBD4B7BrIE8i1D0b0CnoRiacer7px93Yzuwt4GSgB1rn7bjNbGWxfA3wa+DMzawNOALcHV+BMAtYH/w8oBZ5191/m6Fxy4vTMlQp6EYmpHoMewN03AZu6rFuT8fph4OEsx9UCc/pZY6Q6WzcT1KMXkZjSnbE9SDa3MGZ4GUNLNf2BiMSTgr4HDakWfRErIrGmoO9BevoDtW1EJL4U9D1Ij+iHRV2GiEifKeh7oBG9iMSdgv4sjre2c6y1Q5dWikisKejPoqE5fQ29vowVkThT0J9FsnP6A43oRSTGFPRn0Tn9gUb0IhJnCvqz6LwrVj16EYkzBf1ZaPoDESkGoea6KTa1yRRv/rG5x/3+3x8OM25EGWUl+v+hiMTXoAz6//rTGmobjoXa96qLxua2GBGRHBt0QX/g8AlqG47xxUUzWHblGU9EPMMFY4fnoSoRkdwZdEFfXdcIwI2zz+fiSaMjrkZEJPcGXfN5yztNjBlexqXnnRN1KSIieTH4gr6ukXmV4xkyJNszz0VEis+gCvoDh0/wbuNxrp0+IepSRETyZlAFfWd//trp4yOuREQkfwZV0L/+TqP68yIy6AyqoN9S28R89edFZJAZNEH/3uET/KFJ/XkRGXxCBb2ZLTGzvWa2z8xWZdm+zMx+b2Y7zKzGzK4Le2y+VNd29ucV9CIyuPQY9GZWAjwGLAUuA5ab2WVddvtHYI67Xwl8DniiF8fmxZbadH9+1nm6SUpEBpcwI/p5wD53r3X3VuA5YFnmDu6ecncPFkcCHvbYfFF/XkQGqzBBPxnYn7GcCNZ9iJndYmZvAf9AelQf+thcU39eRAazMEGfbQjsZ6xwX+/us4BPAX/Zm2MBzGxF0N+vSSaTIcoKT/15ERnMwgR9ArgwY3kKcKC7nd19MzDDzCb25lh3X+vuVe5eVVFREaKs8F5/p5GxI9SfF5HBKUzQbwNmmlmlmZUDdwAbM3cws4+YmQWv5wLlQGOYY/NhS12j+vMiMmj1OE2xu7eb2V3Ay0AJsM7dd5vZymD7GuDTwJ+ZWRtwArg9+HI267E5OpesEoeOs7/pBJ9bUJnPHysiUjBCzUfv7puATV3Wrcl4/TDwcNhj86m6tglQf15EBq+ivzN2S226P3+JHjIiIoNU8Qe9+vMiMsgVddB39ufVthGRwayog36L+vMiIsUe9I2MU39eRAa5og/6+ZUT1J8XkUGtaIN+f9NxEodO6LGBIjLoFW3QV9cF/fkZ6s+LyOBWtEHf2Z+/+Fz150VkcCvqoFd/XkSkSINe/XkRkQ8UZdBv6Zx/Xv15EZFiDfom9edFRAJFGvSNXDtd/XkRESjCoN/fdJz3Dmt+GxGRTkUX9Fv0fFgRkQ8pwqBvYvzIcmaeOyrqUkRECkIRBr3mnxcRyVRUQa/+vIjImYoq6F9Xf15E5AxFFfRbahvVnxcR6aJogt7dqa5t4trp6s+LiGQKFfRmtsTM9prZPjNblWX7fzKz3we//tnM5mRsqzeznWa2w8xqBrL4TC3tp1jwkQn8u8vPy9WPEBGJpdKedjCzEuAx4AYgAWwzs43uvidjtzrgenc/ZGZLgbXA/Izti9y9YQDrPsOwshL+6tY5Pe8oIjLIhBnRzwP2uXutu7cCzwHLMndw939290PB4hZgysCWKSIifRUm6CcD+zOWE8G67vwX4KWMZQdeMbPtZraiu4PMbIWZ1ZhZTTKZDFGWiIiE0WPrBsj2zaZn3dFsEemgvy5j9QJ3P2Bm5wK/MrO33H3zGW/ovpZ0y4eqqqqs7y8iIr0XZkSfAC7MWJ4CHOi6k5ldATwBLHP3xs717n4g+P0gsJ50K0hERPIkTNBvA2aaWaWZlQN3ABszdzCzi4C/A/6zu/9LxvqRZja68zXwCWDXQBUvIiI967F14+7tZnYX8DJQAqxz991mtjLYvgZ4AJgA/NDMANrdvQqYBKwP1pUCz7r7L3NyJiIikpW5F147vKqqymtqcnbJvYhI0TGz7cEA+wxFc2esiIhkV5AjejNLAu92WT0RyOlNV3lSLOcBOpdCVSznUiznAfk5l6nuXpFtQ0EGfTZmVtPdP0vipFjOA3QuhapYzqVYzgOiPxe1bkREipyCXkSkyMUp6NdGXcAAKZbzAJ1LoSqWcymW84CIzyU2PXoREembOI3oRUSkDxT0IiJFruCDvqenW8VJvp62lQtmts7MDprZrox1483sV2b2dvD7uChrDKubc3nIzN4LPpsdZnZjlDWGYWYXmtlvzexNM9ttZvcE62P3uZzlXGL1uZjZMDPbama/C87jL4L1kX4mBd2jD55u9S9kPN0KWN7l6VaxYWb1QFWun7aVC2b2cSAFPO3uHw3W/RXQ5O7fDf4nPM7dvxplnWF0cy4PASl3/16UtfWGmZ0PnO/ubwSTB24HPgV8hph9Lmc5l/9AjD4XS0/sNdLdU2ZWBrwG3AP8eyL8TAp9RN/j060kP4JnCDR1Wb0M+Gnw+qek/2IWvG7OJXbc/Y/u/kbwuhl4k/RDgWL3uZzlXGLF01LBYlnwy4n4Myn0oO/t060KXainbcXIJHf/I6T/ogLnRlxPf90VPOB+XRzaHZnMbBpwFVBNzD+XLucCMftczKzEzHYAB4FfuXvkn0mhB33op1vFxAJ3nwssBb4YtBCkMDwOzACuBP4I/K9Iq+kFMxsFvADc6+5Ho66nP7KcS+w+F3fvcPcrST+kaZ6ZfTTikgo+6EM93SouivBpW+8HvdXOHuvBiOvpM3d/P/gLegr4MTH5bII+8AvAM+7+d8HqWH4u2c4lrp8LgLsfBv4PsISIP5NCD/oen24VF0X6tK2NwJ3B6zuBv4+wln7p/EsYuIUYfDbBF38/Ad509+9nbIrd59LducTtczGzCjMbG7weDvwp8BYRfyYFfdUNQHA51SN88HSr1dFW1DdmNp30KB4+eNpWbM7FzP4WWEh6utX3gQeBDcDPgIuAPwC3uXvBf8nZzbksJN0ecKAe+HxnT7VQmdl1wKvATuBUsPrrpHvbsfpcznIuy4nR52LpZ2f/lHReDQF+5u7/w8wmEOFnUvBBLyIi/VPorRsREeknBb2ISJFT0IuIFDkFvYhIkVPQi4gUOQW9iEiRU9CLiBQ5Bb1ICGY2LZgr/cfBPOOvBHc+ihQ8Bb1IeDOBx9z9cuAw8OloyxEJR0EvEl6du+8IXm8HpkVXikh4CnqR8FoyXneQnrNIpOAp6EVEipyCXkSkyGn2ShGRIqcRvYhIkVPQi4gUOQW9iEiRU9CLiBQ5Bb2ISJFT0IuIFDkFvYhIkfv/pzMtwuoM1lQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations[evaluations['r2'] > 0].plot.scatter(x='n', y='r2')\n",
    "evaluations.plot.line(x='n', y='r2_cummax')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Ensembles on Covertype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will take a look at a classification problem, and change the AutoML pipeline.\n",
    "\n",
    "#### Exercise 1.3:\n",
    "Download the covertype dataset (id: 180) that we saw in lab 3.\n",
    "First take a stratified subsample of 50% of the data (using `train_test_split`).\n",
    "Then split that data into a train and test set (50%/50%). \n",
    "The train and test sets are now both 25% of the total data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a GamaClassifier, similarly to how the GamaRegressor was initialized, but:\n",
    " - specify the maximum runtime to at least 3 minutes,\n",
    " - set `n_jobs` to 2,\n",
    " - set the metric to accuracy,\n",
    " - specify a different log name,\n",
    "\n",
    "Then start search (`fit`) and evaluate the model on the test data (`score`).\n",
    "Take a short break once it's all running, or ask us a question about the lecture! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Exercise 1.3: Split the data and run GAMA\n",
    "trees = oml.datasets.get_dataset(180)\n",
    "X,y,_,_ = trees.get_data(target=trees.default_target_attribute, dataset_format='dataframe')\n",
    "X_sub, _, y_sub, _ = train_test_split(X, y, stratify=y, train_size=0.5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sub, y_sub, stratify=y_sub, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAMA version 22.0.0.\n",
      "INIT:GamaClassifier(scoring=accuracy,regularize_length=True,max_pipeline_length=None,random_state=None,max_total_time=60,max_eval_time=None,n_jobs=2,max_memory_mb=None,verbosity=20,search=AsyncEA(),post_processing=BestFitPostProcessing(),output_directory=gama_log2,store=logs)\n"
     ]
    }
   ],
   "source": [
    "automl = GamaClassifier(\n",
    "    max_total_time=60,\n",
    "    n_jobs=2,\n",
    "    scoring='accuracy',\n",
    "    verbosity=logging.INFO,  # to get printed updates about search progress\n",
    "    output_directory=\"gama_log2\",  # name for a log file to record search output in\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START: preprocessing default\n",
      "STOP: preprocessing default after 0.7971s.\n",
      "START: search AsyncEA\n",
      "Starting EA with new population.\n",
      "Search phase evaluated 18 individuals.\n",
      "STOP: search AsyncEA after 54.1792s.\n",
      "START: postprocess BestFitPostProcessing\n",
      "STOP: postprocess BestFitPostProcessing after 0.8282s.\n"
     ]
    }
   ],
   "source": [
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.707043988694833"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the model perform? In lab 3 we had about 80% accuracy after tuning the number of trees in the RandomForest. How does this model compare?\n",
    "\n",
    "The covertype dataset is quite large, and three minutes is not much time. For this reason we downsampled such that our training set contained only 25% of the original data. In our experience with these constraints, we find that GAMA can produce models with 80% accuracy, but it's also possible to see worse results. With more time we could search longer and evaluate more models on more of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.4\n",
    "\n",
    "Up to this point GAMA has been using the best found pipeline to make predictions on the test data.\n",
    "However, we saw that constructing ensembles of models can be a useful tool to gain additional performance.\n",
    "GAMA can be configured to automatically build an ensemble from the models it found during search. To do this you should initialize GAMA with the `post_processing_method` specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAMA version 22.0.0.\n",
      "INIT:GamaClassifier(scoring=accuracy,regularize_length=True,max_pipeline_length=None,random_state=None,max_total_time=60,max_eval_time=None,n_jobs=2,max_memory_mb=None,verbosity=20,search=AsyncEA(),post_processing=EnsemblePostProcessing(ensemble_size=25,hillclimb_size=10000,max_models=200),output_directory=gama_log3,store=logs)\n"
     ]
    }
   ],
   "source": [
    "from gama.postprocessing import EnsemblePostProcessing\n",
    "\n",
    "automl_with_ensemble = GamaClassifier(\n",
    "    max_total_time=60,\n",
    "    n_jobs=2,\n",
    "    verbosity=logging.INFO,\n",
    "    output_directory=\"gama_log3\",\n",
    "    scoring='accuracy',\n",
    "    post_processing=EnsemblePostProcessing(),  # Specify to build an ensemble after search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, start search and record the test set score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START: preprocessing default\n",
      "Data has too many features to include PolynomialFeatures\n",
      "STOP: preprocessing default after 0.7525s.\n",
      "START: search AsyncEA\n",
      "Starting EA with new population.\n",
      "Search phase evaluated 19 individuals.\n",
      "STOP: search AsyncEA after 42.1039s.\n",
      "START: postprocess EnsemblePostProcessing\n",
      "Not downsampling because only 10000 samples were stored.\n",
      "Ensemble size 6 , best score: 0.5074\n",
      "Ensemble size 7 , best score: 0.5304\n",
      "Ensemble size 8 , best score: 0.5417\n",
      "Ensemble size 9 , best score: 0.5174\n",
      "Ensemble size 10 , best score: 0.5277\n",
      "Ensemble size 11 , best score: 0.5298\n",
      "Ensemble size 12 , best score: 0.5459\n",
      "Ensemble size 13 , best score: 0.5276\n",
      "Ensemble size 14 , best score: 0.5343\n",
      "Ensemble size 15 , best score: 0.5272\n",
      "Ensemble size 16 , best score: 0.5319\n",
      "Ensemble size 17 , best score: 0.5348\n",
      "Ensemble size 18 , best score: 0.5326\n",
      "Ensemble size 19 , best score: 0.5349\n",
      "Ensemble size 20 , best score: 0.5392\n",
      "Ensemble size 21 , best score: 0.5315\n",
      "Ensemble size 22 , best score: 0.5381\n",
      "Ensemble size 23 , best score: 0.5389\n",
      "Ensemble size 24 , best score: 0.5359\n",
      "Ensemble size 25 , best score: 0.5389\n",
      "Ensemble build took 1.3674507141113281s. Fit with timeout 15.776211738586426s.\n",
      "STOP: postprocess EnsemblePostProcessing after 1.3865s.\n"
     ]
    }
   ],
   "source": [
    "##### Exercise 1.4\n",
    "automl_with_ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble score: 0.5351\n"
     ]
    }
   ],
   "source": [
    "score = automl_with_ensemble.score(X_test, y_test)\n",
    "print(\"ensemble score: {:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.5\n",
    "Note that this run was independent from the previous run. This means it might have found better or worse pipelines than last search. We cannot compare the performance of this ensemble directly to the previous best score. Run the code cell below to see how the single best pipeline would have scored *this* run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.485, test score: 0.486\n"
     ]
    }
   ],
   "source": [
    "# Currently post-hoc switching of post-processing method is not supported directly.\n",
    "# We work around this:\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "best, = automl_with_ensemble._evaluation_library.n_best(1)\n",
    "best_pipeline = best.individual.pipeline\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "test_score = best_pipeline.score(X_test, y_test)\n",
    "print(\"train score: {:.3f}, test score: {:.3f}\".format(best.score[0], test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, did it improve the performance? Was the improvement big? - No it unfortunately did not. It now behaves more or less as random classifier(dataset had was very unbalanced towards one of the classes).\n",
    "\n",
    "Normally the ensemble should perform better, though the benefit can be very marginal.\n",
    "GAMA creates an Ensemble through weighting votes of pipelines evaluated in search (for the interested, the precise procedure is described in [Caruana et al. (2004)](https://www.cs.cornell.edu/~caruana/ctp/ct.papers/caruana.icml04.icdm06long.pdf)).\n",
    "In the scenario and constraints we have set up just now, creating a good ensemble is hard.\n",
    "Can you think of some reason(s) why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Maybe the training did not last long enough to find good pipelines, as a result we have a bunch of very weak pipelines with high bias which can not be corrected by (weighted) averaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n",
    "> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Recognition with AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *note*: If you are running out of time, or are experiencing errors below, ignore the coding assigment. We are aware that in some scenarios GAMA halts on this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.6\n",
    "AutoML is still not (yet) a one-tool-fits-all solution.\n",
    "GAMA was designed to deal with tabular data.\n",
    "Last lab session you trained ConvNets to classify images in the CIFAR dataset.\n",
    "The very first model already had at least 60% accuracy, the best model had ~83% accuracy.\n",
    "We will now compare those results to GAMA:\n",
    " - download the CIFAR-10 dataset from OpenML (dataset id: 40926)\n",
    " - split the data into a train and test set (80%/20%)\n",
    " - run GAMA optimizing for accuracy, with n_jobs=1 and (at least) 5 minutes of runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CIFAR data. Takes a while the first time.\n",
    "# This version returns 3x32x32 resolution images. \n",
    "cifar = oml.datasets.get_dataset(40926) \n",
    "X, y, _, _ = cifar.get_data(target=cifar.default_target_attribute, dataset_format='array')\n",
    "\n",
    "# The dataset (40926) is in a 3x32x32 format, we need to reshape to make the data tabular\n",
    "X = X.reshape((len(X),3 * 32 * 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 3072)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAMA version 22.0.0.\n",
      "INIT:GamaClassifier(scoring=accuracy,regularize_length=True,max_pipeline_length=None,random_state=None,max_total_time=300,max_eval_time=None,n_jobs=2,max_memory_mb=None,verbosity=20,search=AsyncEA(),post_processing=BestFitPostProcessing(),output_directory=gama_log_cifar,store=logs)\n"
     ]
    }
   ],
   "source": [
    "automl = GamaClassifier(\n",
    "    max_total_time=300,\n",
    "    n_jobs=2,\n",
    "    scoring='accuracy',\n",
    "    verbosity=logging.INFO,\n",
    "    output_directory=\"gama_log_cifar\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START: preprocessing default\n",
      "STOP: preprocessing default after 37.4030s.\n",
      "START: search AsyncEA\n",
      "Starting EA with new population.\n",
      "Search phase evaluated 8 individuals.\n",
      "STOP: search AsyncEA after 247.2972s.\n",
      "START: postprocess BestFitPostProcessing\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gama\\GamaClassifier.py:142\u001b[0m, in \u001b[0;36mGamaClassifier.fit\u001b[1;34m(self, x, y, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(m\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39m_score_func)\u001b[38;5;241m.\u001b[39mparameters:\n\u001b[0;32m    140\u001b[0m         m\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39m_kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: y})\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gama\\gama.py:582\u001b[0m, in \u001b[0;36mGama.fit\u001b[1;34m(self, x, y, warm_start)\u001b[0m\n\u001b[0;32m    573\u001b[0m     best_individuals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;28mreversed\u001b[39m(\n\u001b[0;32m    575\u001b[0m             \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         )\n\u001b[0;32m    580\u001b[0m     )\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_processing\u001b[38;5;241m.\u001b[39mdynamic_defaults(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 582\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post_processing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_process\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_time_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_time_remaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbest_individuals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    589\u001b[0m     to_clean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(nothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluations\u001b[39m\u001b[38;5;124m\"\u001b[39m, models\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gama\\postprocessing\\best_fit.py:26\u001b[0m, in \u001b[0;36mBestFitPostProcessing.post_process\u001b[1;34m(self, x, y, timeout, selection)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost_process\u001b[39m(\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m, x: pd\u001b[38;5;241m.\u001b[39mDataFrame, y: pd\u001b[38;5;241m.\u001b[39mSeries, timeout: \u001b[38;5;28mfloat\u001b[39m, selection: List[Individual]\n\u001b[0;32m     25\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_individual \u001b[38;5;241m=\u001b[39m \u001b[43mselection\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_individual\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mfit(x, y)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results will vary wildly.\n",
    "Running it a few times can give scores ranging from ~10% accuracy to ~35% accuracy. \n",
    "More time will lead to better results, but it will not approach ConvNet levels of performance.\n",
    "Why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Maybe all of checked pipelines have less parameters than CNN and so can not have even comparable perfomance. Also all of them are processing images converted to 1D vectors(tabular data) what also disallows them to learn from spatial structures present in data as easy as CNNs do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n",
    "> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Other AutoML tools\n",
    "There are AutoML tools that are specifically designed to automatically learn neural network architectures. For example [AutoKeras](https://autokeras.com/) (Texas A&M University), [AutoGluon](https://autogluon.mxnet.io/) (commercial, Amazon), and [Cloud AutoML](https://cloud.google.com/automl) (commercial, Google). If you are eager, do go and compare your own ConvNet to these AutoML systems instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
